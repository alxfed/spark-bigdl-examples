{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.dataset import transformer\n",
    "from bigdl.nn import criterion\n",
    "from bigdl.nn import layer\n",
    "from bigdl.optim import optimizer\n",
    "from bigdl.util import common\n",
    "import pyspark\n",
    "import os\n",
    "from bigdl.dataset import mnist\n",
    "from bigdl.dataset import transformer\n",
    "import glob\n",
    "import imageio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "    common.create_spark_conf()\n",
    "    .setAppName('bigdl-mnist')\n",
    "    .setMaster(os.environ.get('SPARK_MASTER'))\n",
    "    )\n",
    "conf = conf.set('spark.executor.cores', 1)\n",
    "conf = conf.set('spark.cores.max', 1)\n",
    "##ADD BIGDL_JARS\n",
    "conf.set(\"spark.jars\",os.environ.get('BIGDL_JARS'))\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "common.init_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(class_num):\n",
    "    model = layer.Sequential()\n",
    "    model.add(layer.Reshape([1, 28, 28]))\n",
    "    model.add(layer.SpatialConvolution(1, 6, 5, 5))\n",
    "    model.add(layer.Tanh())\n",
    "    model.add(layer.SpatialMaxPooling(2, 2, 2, 2))\n",
    "    model.add(layer.Tanh())\n",
    "    model.add(layer.SpatialConvolution(6, 12, 5, 5))\n",
    "    model.add(layer.SpatialMaxPooling(2, 2, 2, 2))\n",
    "    model.add(layer.Reshape([12 * 4 * 4]))\n",
    "    model.add(layer.Linear(12 * 4 * 4, 100))\n",
    "    model.add(layer.Tanh())\n",
    "    model.add(layer.Linear(100, class_num))\n",
    "    model.add(layer.LogSoftMax())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Files from local dataset\n",
    "files = glob.glob(os.environ.get('DATA_DIR')+'/train/*.png')\n",
    "def mapper(x):\n",
    "    label = int(x.split('/')[-1].split('-')[-1][:-4])+1\n",
    "    image = imageio.imread('file://'+x).astype(np.float32).reshape(1,28,28)/255\n",
    "    return common.Sample.from_ndarray(image, label)\n",
    "trainRDD = sc.parallelize(files).map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizer.Optimizer(\n",
    "    model=build_model(10),\n",
    "    training_rdd=trainRDD,\n",
    "    criterion=criterion.ClassNLLCriterion(),\n",
    "    optim_method=optimizer.SGD(\n",
    "        learningrate=0.01, learningrate_decay=0.0002\n",
    "    ),\n",
    "    end_trigger=optimizer.MaxEpoch(1),\n",
    "    batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = opt.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('/tmp/mnist')\n",
    "trained_model.saveModel(\n",
    "    '/tmp/mnist/model.pb',\n",
    "    '/tmp/mnist/model.bin',\n",
    "    over_write=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.environ.get('DATA_DIR')+'/test/*.png')\n",
    "validateRDD = sc.parallelize(files).map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trained_model.evaluate(validateRDD,10,[optimizer.Top1Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.environ.get('DATA_DIR')+'/test/*.png')\n",
    "def mapper_test(x):\n",
    "    label = int(x.split('/')[-1].split('-')[-1][:-4])+1\n",
    "    image = imageio.imread('file://'+x).astype(np.float32).reshape(1, 28, 28)/255\n",
    "    return (label,image)\n",
    "testRDD = sc.parallelize(files).map(mapper_test)\n",
    "predictRDD  = testRDD.map(lambda x: common.Sample.from_ndarray(x[1],np.array([2.0])))\n",
    "labelsRDD = testRDD.map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = trained_model.predict(predictRDD).map(lambda x: np.argmax(x)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsRDD.zip(predicts).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}